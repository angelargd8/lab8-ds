{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6016ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: narwhals>=2.0 in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from pyreadstat) (2.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from pyreadstat) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\msi\\desktop\\info\\escritorio\\uvg\\8vo semestre\\data science\\dsvenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyreadstat pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1631e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python sav2xlsx.py /path/to/folder /path/to/output \n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import pyreadstat\n",
    "except ImportError as e:\n",
    "    print(\"ERROR: pyreadstat is required. Install with:\\n  pip install pyreadstat pandas openpyxl\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def build_value_labels_df(value_labels: Dict[str, Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert pyreadstat value labels dict into a tidy DataFrame with columns:\n",
    "    variable, value, label\n",
    "    \"\"\"\n",
    "    rows: List[Tuple[str, str, str]] = []\n",
    "    for var, mapping in value_labels.items():\n",
    "        # mapping is {code: label}\n",
    "        for code, label in mapping.items():\n",
    "            rows.append((var, code, label))\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"variable\", \"value\", \"label\"])\n",
    "    df = pd.DataFrame(rows, columns=[\"variable\", \"value\", \"label\"])\n",
    "    return df.sort_values([\"variable\", \"value\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def build_variable_info_df(meta: \"pyreadstat.metadata_container.MetadataContainer\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a DataFrame summarizing variable metadata.\n",
    "    \"\"\"\n",
    "    names = meta.column_names or []\n",
    "    labels_map = meta.column_names_to_labels or {}\n",
    "    measure_map = meta.measure_levels or {}\n",
    "    formats_map = meta.formats or {}\n",
    "    missing_ranges = meta.missing_ranges or {}\n",
    "    missing_values = meta.missing_user_values or {}\n",
    "\n",
    "    rows = []\n",
    "    for name in names:\n",
    "        rows.append({\n",
    "            \"name\": name,\n",
    "            \"label\": labels_map.get(name, \"\"),\n",
    "            \"measure_level\": measure_map.get(name, \"\"),\n",
    "            \"format\": formats_map.get(name, \"\"),\n",
    "            \"missing_values\": str(missing_values.get(name, \"\")),\n",
    "            \"missing_ranges\": str(missing_ranges.get(name, \"\")),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def convert_file(input_path: Path, output_dir: Path, *, apply_labels: bool, include_metadata: bool, encoding: str, sheet_name: str, suffix: str, overwrite: bool) -> Path:\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(f\"Input not found: {input_path}\")\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_name = input_path.stem + suffix + \".xlsx\"\n",
    "    out_path = output_dir / out_name\n",
    "\n",
    "    if out_path.exists() and not overwrite:\n",
    "        print(f\"SKIP: {out_path} already exists. Use --overwrite to replace.\", file=sys.stderr)\n",
    "        return out_path\n",
    "\n",
    "    read_kwargs = {}\n",
    "    if encoding:\n",
    "        read_kwargs[\"encoding\"] = encoding\n",
    "\n",
    "    print(f\"Reading {input_path} ...\", file=sys.stderr)\n",
    "    df, meta = pyreadstat.read_sav(str(input_path), apply_value_formats=apply_labels, formats_as_category=False, **read_kwargs)\n",
    "\n",
    "    # Write to Excel\n",
    "    print(f\"Writing {out_path} ...\", file=sys.stderr)\n",
    "    with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "        # Data sheet\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "        if include_metadata:\n",
    "            # Variable info\n",
    "            varinfo_df = build_variable_info_df(meta)\n",
    "            varinfo_df.to_excel(writer, index=False, sheet_name=\"Variable_Info\")\n",
    "\n",
    "            # Value labels\n",
    "            labels_df = build_value_labels_df(meta.value_labels or {})\n",
    "            labels_df.to_excel(writer, index=False, sheet_name=\"Value_Labels\")\n",
    "\n",
    "            # File-level info\n",
    "            fileinfo_rows = [\n",
    "                (\"file_label\", meta.file_label or \"\"),\n",
    "                (\"number_of_variables\", len(meta.column_names or [])),\n",
    "                (\"number_of_rows\", len(df)),\n",
    "                (\"weight_variable\", meta.weight_variable or \"\"),\n",
    "                (\"document\", (meta.document or \"\").strip() if meta.document else \"\"),\n",
    "            ]\n",
    "            fileinfo_df = pd.DataFrame(fileinfo_rows, columns=[\"key\", \"value\"])\n",
    "            fileinfo_df.to_excel(writer, index=False, sheet_name=\"File_Info\")\n",
    "\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def find_sav_files(root: Path) -> List[Path]:\n",
    "    if root.is_file() and root.suffix.lower() == \".sav\":\n",
    "        return [root]\n",
    "    # Search recursively\n",
    "    return sorted(root.rglob(\"*.sav\"))\n",
    "\n",
    "\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    p = argparse.ArgumentParser(description=\"Convert SPSS .sav to Excel .xlsx\")\n",
    "    p.add_argument(\"input\", help=\"Path to a .sav file or a directory containing .sav files\")\n",
    "    p.add_argument(\"output_dir\", nargs=\"?\", default=None, help=\"Optional output directory (defaults to INPUT's folder)\")\n",
    "    p.add_argument(\"--apply-labels\", action=\"store_true\", help=\"Replace codes by value labels where available\")\n",
    "    p.add_argument(\"--include-metadata\", action=\"store_true\", help=\"Add sheets with variable info and value labels\")\n",
    "    p.add_argument(\"--encoding\", default=\"\", help=\"Force file text encoding (rarely needed)\")\n",
    "    p.add_argument(\"--sheet-name\", default=\"Data\", help=\"Excel sheet name for the main data\")\n",
    "    p.add_argument(\"--suffix\", default=\"_converted\", help=\"Suffix appended to output filename before .xlsx\")\n",
    "    p.add_argument(\"--overwrite\", action=\"store_true\", help=\"Overwrite existing output files\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "def main() -> int:\n",
    "    args = parse_args()\n",
    "    input_path = Path(args.input).expanduser().resolve()\n",
    "\n",
    "    if args.output_dir:\n",
    "        output_dir = Path(args.output_dir).expanduser().resolve()\n",
    "    else:\n",
    "        output_dir = (input_path.parent if input_path.is_file() else input_path)\n",
    "\n",
    "    sav_files = find_sav_files(input_path)\n",
    "    if not sav_files:\n",
    "        print(f\"No .sav files found under: {input_path}\", file=sys.stderr)\n",
    "        return 2\n",
    "\n",
    "    successes = 0\n",
    "    failures = 0\n",
    "    outputs: List[Path] = []\n",
    "\n",
    "    for sav in sav_files:\n",
    "        try:\n",
    "            out = convert_file(\n",
    "                sav, output_dir,\n",
    "                apply_labels=args.apply_labels,\n",
    "                include_metadata=args.include_metadata,\n",
    "                encoding=args.encoding,\n",
    "                sheet_name=args.sheet_name,\n",
    "                suffix=args.suffix,\n",
    "                overwrite=args.overwrite\n",
    "            )\n",
    "            outputs.append(out)\n",
    "            successes += 1\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR converting {sav}: {e}\", file=sys.stderr)\n",
    "            failures += 1\n",
    "\n",
    "    print(f\"Done. Converted: {successes}, Failed: {failures}\", file=sys.stderr)\n",
    "    if outputs:\n",
    "        print(\"\\nOutput files:\", file=sys.stderr)\n",
    "        for p in outputs:\n",
    "            print(f\" - {p}\", file=sys.stderr)\n",
    "\n",
    "    return 0 if failures == 0 else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKDIR = Path(\"/working_dir\")\n",
    "FOLDERNAMES = [\n",
    "    \"fallecidos/\",\n",
    "    \"vehiculos involucrados/\",\n",
    "    \"hechos y transito/\",\n",
    "]\n",
    "\n",
    "APPLY_LABELS = True\n",
    "INCLUDE_METADATA = True\n",
    "ENCODING = \"\"\n",
    "SHEET_NAME = \"Data\"\n",
    "SUFFIX = \"_converted\"\n",
    "OVERWRITE = True\n",
    "\n",
    "# Recorre carpetas y convierte\n",
    "outputs = []\n",
    "errors = []\n",
    "\n",
    "for folder in FOLDERNAMES:\n",
    "    folder_path = WORKDIR / folder\n",
    "    if not folder_path.exists():\n",
    "        print(f\"AVISO: no existe {folder_path}, se omite.\")\n",
    "        continue\n",
    "\n",
    "    sav_files = find_sav_files(folder_path)\n",
    "    if not sav_files:\n",
    "        print(f\"Sin .sav en {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for sav in sav_files:\n",
    "        try:\n",
    "            out = convert_file(\n",
    "                input_path=sav,\n",
    "                output_dir=sav.parent,          # mismo directorio que el .sav\n",
    "                apply_labels=APPLY_LABELS,\n",
    "                include_metadata=INCLUDE_METADATA,\n",
    "                encoding=ENCODING,\n",
    "                sheet_name=SHEET_NAME,\n",
    "                suffix=SUFFIX,\n",
    "                overwrite=OVERWRITE\n",
    "            )\n",
    "            print(f\"OK → {out}\")\n",
    "            outputs.append(out)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR con {sav}: {e}\")\n",
    "            errors.append((sav, e))\n",
    "\n",
    "print(f\"\\nResumen: {len(outputs)} convertidos, {len(errors)} con error\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsvenv)",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
